import os
import pandas as pd
import matplotlib
matplotlib.use('Agg')  # –î–ª—è —Ä–∞–±–æ—Ç—ã –±–µ–∑ GUI
import matplotlib.pyplot as plt
import re
from telegram import Update, ReplyKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from dotenv import load_dotenv
from difflib import get_close_matches
import openai
import io
import seaborn as sns

load_dotenv()
TELEGRAM_TOKEN = os.getenv('TELEGRAM_TOKEN')
SHEET_ID = os.getenv('SHEET_ID')
GOOGLE_JSON = os.getenv('GOOGLE_JSON_PATH', 'medical-462021-78bf30c680aa.json')
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')

# –°–æ–∑–¥–∞—ë–º –∫–ª–∏–µ–Ω—Ç–∞ OpenAI (–≥–ª–æ–±–∞–ª—å–Ω–æ)
client = openai.OpenAI(api_key=OPENAI_API_KEY)

COLUMN_SYNONYMS = {
    "—Ç–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è": "–° –∫–∞–∫–æ–π —Ü–µ–ª—å—é –≤—ã –ø–æ—Å–µ—Ç–∏–ª–∏ –æ—Ç–¥–µ–ª–µ–Ω–∏–µ –±–∞–Ω–∫–∞?",
    "—Ü–µ–ª—å": "–° –∫–∞–∫–æ–π —Ü–µ–ª—å—é –≤—ã –ø–æ—Å–µ—Ç–∏–ª–∏ –æ—Ç–¥–µ–ª–µ–Ω–∏–µ –±–∞–Ω–∫–∞?",
    "–æ—á–µ—Ä–µ–¥—å": "–°–∫–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã –æ–±—ã—á–Ω–æ –∂–¥–µ—Ç–µ –≤ –æ—á–µ—Ä–µ–¥–∏ –¥–æ –ø–æ–ª—É—á–µ–Ω–∏—è –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è?",
    "–±–∞–Ω–∫": "–ù–∞–∑–æ–≤–∏—Ç–µ –±–∞–Ω–∫, –æ—Ç–¥–µ–ª–µ–Ω–∏–µ –∫–æ—Ç–æ—Ä–æ–≥–æ –≤—ã –ø–æ—Å–µ—â–∞–ª–∏ –Ω–µ–¥–∞–≤–Ω–æ.",
    "–æ—Ç–¥–µ–ª–µ–Ω–∏–µ": "–ù–∞–∑–æ–≤–∏—Ç–µ –±–∞–Ω–∫, –æ—Ç–¥–µ–ª–µ–Ω–∏–µ –∫–æ—Ç–æ—Ä–æ–≥–æ –≤—ã –ø–æ—Å–µ—â–∞–ª–∏ –Ω–µ–¥–∞–≤–Ω–æ.",
    "—Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ": "–ö–∞–∫ –≤—ã –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç–µ —É–¥–æ–±—Å—Ç–≤–æ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏—è –æ—Ç–¥–µ–ª–µ–Ω–∏—è –±–∞–Ω–∫–∞?",
    "–≤–µ–∂–ª–∏–≤–æ—Å—Ç—å": "–ù–∞—Å–∫–æ–ª—å–∫–æ –≤–µ–∂–ª–∏–≤—ã –∏ –¥–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏ –±–∞–Ω–∫–∞?",
    "–∫–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å": "–ö–∞–∫ –≤—ã –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –≤ —Ä–µ—à–µ–Ω–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤?",
    "–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å": "–ö–∞–∫ –≤—ã –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –±–∞–Ω–∫–æ–≤—Å–∫–∏—Ö —É—Å–ª—É–≥–∞—Ö –≤ –æ—Ç–¥–µ–ª–µ–Ω–∏–∏?",
    "—Ç–µ—Ä–º–∏–Ω–∞–ª": "–£–¥–æ–±–Ω–æ –ª–∏ –≤–∞–º –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã–º–∏ —Ç–µ—Ä–º–∏–Ω–∞–ª–∞–º–∏ –∏–ª–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–º?",
    "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è": "–ü–æ—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª–∏ –±—ã –≤—ã —ç—Ç–æ –æ—Ç–¥–µ–ª–µ–Ω–∏–µ –±–∞–Ω–∫–∞ —Å–≤–æ–∏–º –¥—Ä—É–∑—å—è–º –∏ –∑–Ω–∞–∫–æ–º—ã–º?",
    "–ø–æ–Ω—è—Ç–Ω–æ": "–ù–∞—Å–∫–æ–ª—å–∫–æ –ø–æ–Ω—è—Ç–Ω–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏ –æ–±—ä—è—Å–Ω—è—é—Ç —É—Å–ª–æ–≤–∏—è –±–∞–Ω–∫–æ–≤—Å–∫–∏—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤ (–∫—Ä–µ–¥–∏—Ç—ã, –≤–∫–ª–∞–¥—ã –∏ —Ç.–ø.)?",
    "—á–∏—Å—Ç–æ—Ç–∞": "–ö–∞–∫ –≤—ã –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç–µ —á–∏—Å—Ç–æ—Ç—É –∏ –∫–æ–º—Ñ–æ—Ä—Ç –≤ –ø–æ–º–µ—â–µ–Ω–∏–∏ –æ—Ç–¥–µ–ª–µ–Ω–∏—è?",
    "–ø—Ä–æ–±–ª–µ–º": "–ë—ã–ª–∏ –ª–∏ —É –≤–∞—Å —Å–ª—É—á–∞–∏, –∫–æ–≥–¥–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å –Ω–µ —Ä–µ—à–∏–ª—Å—è?",
    "–∂–∞–ª–æ–±": "–ë—ã–ª–∏ –ª–∏ —É –≤–∞—Å —Å–ª—É—á–∞–∏, –∫–æ–≥–¥–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å –Ω–µ —Ä–µ—à–∏–ª—Å—è?",
    "–ø–æ–ª": "–£–∫–∞–∂–∏—Ç–µ –≤–∞—à –ø–æ–ª.",
    "gender": "–£–∫–∞–∂–∏—Ç–µ –≤–∞—à –ø–æ–ª.",
    "–≤–æ–∑—Ä–∞—Å—Ç": "–£–∫–∞–∂–∏—Ç–µ –≤–∞—à –≤–æ–∑—Ä–∞—Å—Ç.",
}

def get_df_from_gsheet():
    try:
        scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
        google_credentials = os.getenv('GOOGLE_CREDENTIALS')
        if google_credentials:
            import json
            creds = ServiceAccountCredentials.from_json_keyfile_dict(
                json.loads(google_credentials), scope
            )
        else:
            # Fallback –∫ —Ñ–∞–π–ª—É (–¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏)
            if not os.path.exists(GOOGLE_JSON):
                print(f"–§–∞–π–ª {GOOGLE_JSON} –Ω–µ –Ω–∞–π–¥–µ–Ω –∏ GOOGLE_CREDENTIALS –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
                return pd.DataFrame()
            creds = ServiceAccountCredentials.from_json_keyfile_name(GOOGLE_JSON, scope)
        
        client = gspread.authorize(creds)
        sheet = client.open_by_key(SHEET_ID).worksheet("–û—Ç–≤–µ—Ç—ã –Ω–∞ —Ñ–æ—Ä–º—É")
        data = sheet.get_all_records()
        return pd.DataFrame(data)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Google Sheets: {e}")
        return pd.DataFrame()

def extract_numeric(series):
    return pd.to_numeric(series.astype(str).str.extract('(\d+)')[0], errors='coerce')

def find_column_by_synonym(df, text):
    text = text.lower()
    for short, real in COLUMN_SYNONYMS.items():
        if short in text and real in df.columns:
            return real
    return None

def find_column_fuzzy(df, text):
    candidates = list(df.columns)
    text_clean = re.sub(r'[^–∞-—èa-z0-9 ]', '', text.lower())
    match = get_close_matches(text_clean, [re.sub(r'[^–∞-—èa-z0-9 ]', '', c.lower()) for c in candidates], n=1, cutoff=0.3)
    if match:
        for c in candidates:
            if match[0] in re.sub(r'[^–∞-—èa-z0-9 ]', '', c.lower()):
                return c
    words = text_clean.split()
    for c in candidates:
        col_clean = re.sub(r'[^–∞-—èa-z0-9 ]', '', c.lower())
        if any(w in col_clean for w in words if len(w) > 2):
            return c
    return None

def plot_pie(df, column, title):
    plt.style.use('seaborn-v0_8-darkgrid')
    data = df[column].value_counts()
    labels = [str(x)[:18] + ('...' if len(str(x)) > 18 else '') for x in data.index]
    colors = sns.color_palette('Set3', len(data))
    plt.figure(figsize=(5, 5))
    wedges, texts, autotexts = plt.pie(
        data.values,
        labels=labels,
        autopct='%1.1f%%',
        startangle=140,
        colors=colors,
        textprops={'fontsize': 12, 'fontweight': 'bold'},
        wedgeprops={'edgecolor': 'white'}
    )
    plt.title(f'üü¢ {title}', fontsize=17, fontweight='bold', pad=15)
    plt.tight_layout()
    buf = io.BytesIO()
    plt.savefig(buf, format='png', dpi=180, bbox_inches='tight')
    plt.close()
    buf.seek(0)
    return buf

def plot_hist(df, column, title):
    plt.style.use('seaborn-v0_8-darkgrid')
    data = extract_numeric(df[column]).dropna()
    plt.figure(figsize=(8, 5))
    ax = sns.histplot(data, bins=range(int(data.min()), int(data.max())+5, 5), color='#4C72B0', edgecolor='black', alpha=0.85)
    ax.set_title(f'üìà {title}', fontsize=17, fontweight='bold', pad=15)
    ax.set_xlabel(column, fontsize=13, fontweight='bold')
    ax.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', fontsize=13, fontweight='bold')
    plt.xticks(fontsize=11)
    plt.yticks(fontsize=11)
    sns.despine()
    plt.tight_layout()
    buf = io.BytesIO()
    plt.savefig(buf, format='png', dpi=180, bbox_inches='tight')
    plt.close()
    buf.seek(0)
    return buf

def plot_bar(df, column, title):
    plt.style.use('seaborn-v0_8-darkgrid')
    plt.figure(figsize=(9, 5))
    data = df[column].value_counts()
    # –û–±—Ä–µ–∑–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ –ø–æ–¥–ø–∏—Å–∏
    labels = [str(x)[:18] + ('...' if len(str(x)) > 18 else '') for x in data.index]
    ax = sns.barplot(x=labels, y=data.values, palette='Set2', edgecolor='black')
    ax.set_title(f'üìä {title}', fontsize=18, fontweight='bold', pad=15)
    ax.set_xlabel(column, fontsize=13, fontweight='bold')
    ax.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', fontsize=13, fontweight='bold')
    plt.xticks(rotation=30, ha='right', fontsize=11)
    plt.yticks(fontsize=11)
    # –ü–æ–¥–ø–∏—Å–∏ –∑–Ω–∞—á–µ–Ω–∏–π
    for i, v in enumerate(data.values):
        ax.text(i, v + max(data.values)*0.01, str(v), ha='center', va='bottom', fontsize=11, fontweight='bold', color='#333')
    sns.despine()
    plt.tight_layout()
    buf = io.BytesIO()
    plt.savefig(buf, format='png', dpi=180, bbox_inches='tight')
    plt.close()
    buf.seek(0)
    return buf

def ask_openai(question, df):
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –≤—Å–µ–º –∫–æ–ª–æ–Ω–∫–∞–º –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
    stats = {}
    for col in df.columns:
        if df[col].dtype == 'object':  # –¢–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            value_counts = df[col].value_counts()
            if not value_counts.empty:
                stats[col] = {
                    'type': 'categorical',
                    'total': len(df[col].dropna()),
                    'unique_values': len(value_counts),
                    'top_values': value_counts.head(3).to_dict()
                }
        else:  # –ß–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            numeric_data = pd.to_numeric(df[col], errors='coerce').dropna()
            if not numeric_data.empty:
                stats[col] = {
                    'type': 'numeric',
                    'total': len(numeric_data),
                    'mean': numeric_data.mean(),
                    'median': numeric_data.median(),
                    'min': numeric_data.min(),
                    'max': numeric_data.max()
                }
    
    # –ü—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö (—Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤)
    sample_data = df.head(5).to_dict('records')
    
    prompt = (
        f"–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫-–ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ–ø—Ä–æ—Å–æ–≤ –±–∞–Ω–∫–æ–≤—Å–∫–∏—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤. "
        f"–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –±—É–¥—å –æ–±—â–∏—Ç–µ–ª—å–Ω—ã–º –∏ –ø–æ–ª–µ–∑–Ω—ã–º.\n\n"
        f"–î–∞–Ω–Ω—ã–µ –æ–ø—Ä–æ—Å–∞:\n"
        f"- –í—Å–µ–≥–æ –∞–Ω–∫–µ—Ç: {len(df)}\n"
        f"- –í–æ–ø—Ä–æ—Å—ã –≤ –æ–ø—Ä–æ—Å–µ: {', '.join(df.columns)}\n\n"
        f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º:\n"
    )
    
    for col, stat in stats.items():
        if stat['type'] == 'categorical':
            top_items = ', '.join([f"{k} ({v})" for k, v in list(stat['top_values'].items())[:3]])
            prompt += f"- {col}: {stat['total']} –æ—Ç–≤–µ—Ç–æ–≤, —Ç–æ–ø: {top_items}\n"
        else:
            prompt += f"- {col}: —Å—Ä–µ–¥–Ω–µ–µ {stat['mean']:.1f}, –º–µ–¥–∏–∞–Ω–∞ {stat['median']:.1f}, –¥–∏–∞–ø–∞–∑–æ–Ω {stat['min']}-{stat['max']}\n"
    
    prompt += f"\n–ü—Ä–∏–º–µ—Ä—ã –æ—Ç–≤–µ—Ç–æ–≤:\n"
    for i, record in enumerate(sample_data, 1):
        prompt += f"–ê–Ω–∫–µ—Ç–∞ {i}: {str(record)[:200]}...\n"
    
    prompt += f"\n–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {question}\n\n"
    prompt += (
        f"–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏:\n"
        f"1. –û—Ç–≤–µ—á–∞–π –¥—Ä—É–∂–µ–ª—é–±–Ω–æ –∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–æ\n"
        f"2. –ï—Å–ª–∏ –º–æ–∂–µ—à—å –æ—Ç–≤–µ—Ç–∏—Ç—å –ø–æ –¥–∞–Ω–Ω—ã–º - –∏—Å–ø–æ–ª—å–∑—É–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤—ã—à–µ\n"
        f"3. –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ - —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º —á–µ—Å—Ç–Ω–æ\n"
        f"4. –ü—Ä–µ–¥–ª–∞–≥–∞–π –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ –≥—Ä–∞—Ñ–∏–∫–∏\n"
        f"5. –ë—É–¥—å –ø–æ–ª–µ–∑–Ω—ã–º –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º\n"
        f"6. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ"
    )
    
    completion = client.chat.completions.create(
        model="gpt-4-1106-preview",
        messages=[
            {"role": "system", "content": "–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫-–ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –±–∞–Ω–∫–æ–≤—Å–∫–∏—Ö –æ–ø—Ä–æ—Å–æ–≤. –û—Ç–≤–µ—á–∞–π —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–æ, –ø–æ–ª–µ–∑–Ω–æ –∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."},
            {"role": "user", "content": prompt}
        ],
        max_tokens=500,
        temperature=0.7
    )
    return completion.choices[0].message.content

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    keyboard = [
        ['üìä –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç', 'üéØ –ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑'],
        ['üë• –ì–µ–Ω–¥–µ—Ä–Ω—ã–π —Å–æ—Å—Ç–∞–≤', 'üìà –í–æ–∑—Ä–∞—Å—Ç–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞'],
        ['üè¶ –¢–æ–ø –±–∞–Ω–∫–æ–≤', 'üíº –¶–µ–ª–∏ –ø–æ—Å–µ—â–µ–Ω–∏—è'],
        ['‚≠ê –û—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞', '‚è∞ –í—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è'],
        ['üîç –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑', 'üìã –í—Å–µ –≤–æ–ø—Ä–æ—Å—ã']
    ]
    reply_markup = ReplyKeyboardMarkup(keyboard, resize_keyboard=True, one_time_keyboard=False)
    
    welcome_text = (
        "ü§ñ *–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ AI-–∞–Ω–∞–ª–∏—Ç–∏–∫ –±–∞–Ω–∫–æ–≤—Å–∫–∏—Ö –æ–ø—Ä–æ—Å–æ–≤!*\n\n"
        "–Ø –ø–æ–º–æ–≥—É –≤–∞–º –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –æ–ø—Ä–æ—Å–∞ –±–∞–Ω–∫–æ–≤—Å–∫–∏—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤:\n\n"
        "üìä *–ß—Ç–æ —è —É–º–µ—é:*\n"
        "‚Ä¢ –°–æ–∑–¥–∞–≤–∞—Ç—å –∫—Ä–∞—Å–∏–≤—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ –∏ –¥–∏–∞–≥—Ä–∞–º–º—ã\n"
        "‚Ä¢ –ü—Ä–æ–≤–æ–¥–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑\n"
        "‚Ä¢ –û—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –ª—é–±—ã–µ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –¥–∞–Ω–Ω—ã–º\n"
        "‚Ä¢ –î–∞–≤–∞—Ç—å —É–º–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n\n"
        "üí° *–ü—Ä–∏–º–µ—Ä—ã –∑–∞–ø—Ä–æ—Å–æ–≤:*\n"
        "‚Ä¢ \"–ö–∞–∫–∏–µ –±–∞–Ω–∫–∏ —Å–∞–º—ã–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ?\"\n"
        "‚Ä¢ \"–°—Ä–∞–≤–Ω–∏ –º—É–∂—á–∏–Ω –∏ –∂–µ–Ω—â–∏–Ω\"\n"
        "‚Ä¢ \"–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º –∫–ª–∏–µ–Ω—Ç–æ–≤\"\n"
        "‚Ä¢ \"–ì—Ä–∞—Ñ–∏–∫ –ø–æ –≤–æ–∑—Ä–∞—Å—Ç—É\"\n"
        "‚Ä¢ \"–ö–∞—á–µ—Å—Ç–≤–æ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è\"\n\n"
        "üéØ *–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏ –∏–ª–∏ –ø–∏—à–∏—Ç–µ —Å–≤–æ–∏ –≤–æ–ø—Ä–æ—Å—ã!*"
    )
    
    await update.message.reply_text(welcome_text, reply_markup=reply_markup, parse_mode='Markdown')

def get_stats_for_gpt(df):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫—Ä–∞—Ç–∫—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –≤—Å–µ–º –∫–ª—é—á–µ–≤—ã–º –≤–æ–ø—Ä–æ—Å–∞–º –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ GPT"""
    stats = ""
    for col in df.columns:
        val = df[col].value_counts()
        if len(val) > 0:
            total = val.sum()
            top = val.idxmax()
            top_count = val.max()
            percent = (top_count / total) * 100
            stats += f"\n- {col}: –≤—Å–µ–≥–æ {total}, —Ç–æ–ø: '{top}' ({top_count}, {percent:.1f}%)"
            if len(val) > 1:
                stats += f", –¥—Ä—É–≥–∏–µ: " + ", ".join([f"{k} ({v})" for k, v in val.head(3).items()])
    return stats

def smart_analytics_gpt(user_query, df):
    stats = get_stats_for_gpt(df)
    prompt = f'''
–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –æ–ø—Ä–æ—Å–æ–≤. –í–æ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–∞–Ω–Ω—ã–º:{stats}
–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç: {user_query}

–û—Ç–≤–µ—á–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–æ –∏ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–º—ã—Å–ª–æ–≤–æ–≥–æ –±–ª–æ–∫–∞:
- üìù –í—ã–≤–æ–¥
- üìä –ö–ª—é—á–µ–≤—ã–µ —Ü–∏—Ñ—Ä—ã
- üîç –ü—Ä–∏—á–∏–Ω—ã/–æ–±—ä—è—Å–Ω–µ–Ω–∏—è
- üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
- üöÄ –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥
–ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å —Å—Ä–∞–≤–Ω–µ–Ω–∏—è ‚Äî —Å—Ä–∞–≤–Ω–∏ –≥—Ä—É–ø–ø—ã —Å —ç–º–æ–¥–∑–∏. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –∞–Ω–∞–ª–∏–∑–∞ ‚Äî –¥–∞–π –ø—Ä–∏—á–∏–Ω—ã –∏ —Å–æ–≤–µ—Ç—ã. –ï—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –¥–∞–Ω–Ω—ã—Ö ‚Äî —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏. –í—Å–µ–≥–¥–∞ –ø—Ä–µ–¥–ª–∞–≥–∞–π —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –ü–∏—à–∏ –∫—Ä–∞—Ç–∫–æ, –ø–æ–Ω—è—Ç–Ω–æ, –ø–æ –¥–µ–ª—É, –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
'''
    response = client.chat.completions.create(
        model="gpt-4-1106-preview",
        messages=[
            {"role": "system", "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –æ–ø—Ä–æ—Å–æ–≤, –æ—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, –ø–æ –¥–µ–ª—É, –¥—Ä—É–∂–µ–ª—é–±–Ω–æ, –Ω–∞ —Ä—É—Å—Å–∫–æ–º."},
            {"role": "user", "content": prompt}
        ],
        max_tokens=700,
        temperature=0.7
    )
    return response.choices[0].message.content

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = update.message.text.lower()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    if not TELEGRAM_TOKEN or not SHEET_ID or not OPENAI_API_KEY:
        await update.message.reply_text("–û—à–∏–±–∫–∞: –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è (TELEGRAM_TOKEN, SHEET_ID, OPENAI_API_KEY)")
        return
    
    df = get_df_from_gsheet()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—É—á–µ–Ω—ã
    if df.empty:
        await update.message.reply_text("–û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã")
        return

    # --- –ö–Ω–æ–ø–∫–∏ ---
    if text == 'üìä –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç' or text == '–ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç':
        summary = analyze_survey(df)
        if len(summary) > 4000:
            parts = []
            current_part = ""
            lines = summary.split('\n')
            for line in lines:
                if len(current_part + line + '\n') > 4000:
                    parts.append(current_part)
                    current_part = line + '\n'
                else:
                    current_part += line + '\n'
            if current_part:
                parts.append(current_part)
            for i, part in enumerate(parts, 1):
                if len(parts) > 1:
                    header = f"üìä –ü–û–õ–ù–´–ô –û–¢–ß–ï–¢ (—á–∞—Å—Ç—å {i}/{len(parts)})\n{'='*30}\n\n"
                    await update.message.reply_text(header + part)
                else:
                    await update.message.reply_text(part)
        else:
            await update.message.reply_text(summary)
        return
    elif text == 'üéØ –±—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑' or text == '–±—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑':
        quick_analysis = generate_quick_analysis(df)
        await update.message.reply_text(quick_analysis, parse_mode='Markdown')
        return
    elif text == 'üë• –≥–µ–Ω–¥–µ—Ä–Ω—ã–π —Å–æ—Å—Ç–∞–≤' or text == '–≥–µ–Ω–¥–µ—Ä–Ω—ã–π —Å–æ—Å—Ç–∞–≤':
        col = COLUMN_SYNONYMS['–ø–æ–ª']
        freq = df[col].value_counts()
        if len(freq) > 0:
            buf = plot_pie(df, col, '–ì–µ–Ω–¥–µ—Ä–Ω—ã–π —Å–æ—Å—Ç–∞–≤')
            if buf:
                await update.message.reply_photo(buf)
                total = freq.sum()
                male_count = freq.get('–ú—É–∂—Å–∫–æ–π', 0)
                female_count = freq.get('–ñ–µ–Ω—Å–∫–∏–π', 0)
                stats_text = f"üë• *–ì–ï–ù–î–ï–†–ù–´–ô –°–û–°–¢–ê–í –û–ü–†–û–®–ï–ù–ù–´–•*\n\n"
                stats_text += f"üìä *–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:*\n"
                stats_text += f"‚Ä¢ –í—Å–µ–≥–æ –æ—Ç–≤–µ—Ç–æ–≤: {total}\n"
                stats_text += f"‚Ä¢ –ú—É–∂—á–∏–Ω: {male_count} ({male_count/total*100:.1f}%)\n"
                stats_text += f"‚Ä¢ –ñ–µ–Ω—â–∏–Ω: {female_count} ({female_count/total*100:.1f}%)\n\n"
                if male_count > female_count:
                    stats_text += f"üèÜ –ë–æ–ª—å—à–µ –º—É–∂—á–∏–Ω –Ω–∞ {male_count - female_count} —á–µ–ª–æ–≤–µ–∫"
                elif female_count > male_count:
                    stats_text += f"üèÜ –ë–æ–ª—å—à–µ –∂–µ–Ω—â–∏–Ω –Ω–∞ {female_count - male_count} —á–µ–ª–æ–≤–µ–∫"
                else:
                    stats_text += f"‚öñÔ∏è –†–∞–≤–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º—É–∂—á–∏–Ω –∏ –∂–µ–Ω—â–∏–Ω"
                await update.message.reply_text(stats_text, parse_mode='Markdown')
            else:
                await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫ - –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
        else:
            await update.message.reply_text("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ–ª–µ —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–æ–≤")
        return
    elif text == 'üìà –≤–æ–∑—Ä–∞—Å—Ç–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞' or text == '–≤–æ–∑—Ä–∞—Å—Ç–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞':
        col = COLUMN_SYNONYMS['–≤–æ–∑—Ä–∞—Å—Ç']
        numeric_data = extract_numeric(df[col]).dropna()
        
        if len(numeric_data) > 0:
            buf = plot_hist(df, col, '–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –≤–æ–∑—Ä–∞—Å—Ç—É')
            if buf:
                await update.message.reply_photo(buf)
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                stats_text = f"üìä *–†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –í–û–ó–†–ê–°–¢–£*\n\n"
                stats_text += f"üìà *–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:*\n"
                stats_text += f"‚Ä¢ –í—Å–µ–≥–æ –æ—Ç–≤–µ—Ç–æ–≤: {len(numeric_data)}\n"
                stats_text += f"‚Ä¢ –°—Ä–µ–¥–Ω–∏–π –≤–æ–∑—Ä–∞—Å—Ç: {numeric_data.mean():.1f} –ª–µ—Ç\n"
                stats_text += f"‚Ä¢ –ú–µ–¥–∏–∞–Ω–Ω—ã–π –≤–æ–∑—Ä–∞—Å—Ç: {numeric_data.median():.1f} –ª–µ—Ç\n"
                stats_text += f"‚Ä¢ –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –≤–æ–∑—Ä–∞—Å—Ç: {numeric_data.min()} –ª–µ—Ç\n"
                stats_text += f"‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –≤–æ–∑—Ä–∞—Å—Ç: {numeric_data.max()} –ª–µ—Ç\n\n"
                
                # –¢–æ–ø –≤–æ–∑—Ä–∞—Å—Ç–æ–≤
                age_counts = numeric_data.value_counts().head(3)
                stats_text += f"üèÜ *–°–∞–º—ã–µ —á–∞—Å—Ç—ã–µ –≤–æ–∑—Ä–∞—Å—Ç—ã:*\n"
                for i, (age, count) in enumerate(age_counts.items(), 1):
                    stats_text += f"{i}. {age} –ª–µ—Ç: {count} —á–µ–ª–æ–≤–µ–∫\n"
                
                await update.message.reply_text(stats_text, parse_mode='Markdown')
            else:
                await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫ - –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
        else:
            await update.message.reply_text("–ù–µ—Ç —á–∏—Å–ª–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –æ –≤–æ–∑—Ä–∞—Å—Ç–µ")
        return
        
    elif text == 'üè¶ —Ç–æ–ø –±–∞–Ω–∫–æ–≤' or text == '—Ç–æ–ø –±–∞–Ω–∫–æ–≤':
        col = COLUMN_SYNONYMS['–±–∞–Ω–∫']
        freq = df[col].value_counts()
        if len(freq) > 0:
            buf = plot_bar(df, col, '–¢–æ–ø –±–∞–Ω–∫–æ–≤')
            if buf:
                await update.message.reply_photo(buf)
                # –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø–æ –±–∞–Ω–∫–∞–º
                analysis = smart_analytics_gpt('–î–∞–π –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ –ø–æ —Ç–æ–ø—É –±–∞–Ω–∫–æ–≤', df)
                await update.message.reply_text(analysis)
            else:
                await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫ - –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
        else:
            await update.message.reply_text("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –±–∞–Ω–∫–∞—Ö")
        return
        
    elif text == 'üíº —Ü–µ–ª–∏ –ø–æ—Å–µ—â–µ–Ω–∏—è' or text == '—Ü–µ–ª–∏ –ø–æ—Å–µ—â–µ–Ω–∏—è':
        col = COLUMN_SYNONYMS['—Ç–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è']
        freq = df[col].value_counts()
        if len(freq) > 0:
            buf = plot_bar(df, col, '–¶–µ–ª–∏ –ø–æ—Å–µ—â–µ–Ω–∏—è –±–∞–Ω–∫–∞')
            if buf:
                await update.message.reply_photo(buf)
                # –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø–æ —Ü–µ–ª—è–º
                analysis = smart_analytics_gpt('–î–∞–π –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ –ø–æ —Ü–µ–ª—è–º –ø–æ—Å–µ—â–µ–Ω–∏—è –±–∞–Ω–∫–∞', df)
                await update.message.reply_text(analysis)
            else:
                await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫ - –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
        else:
            await update.message.reply_text("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ —Ü–µ–ª—è—Ö –ø–æ—Å–µ—â–µ–Ω–∏—è")
        return
        
    elif text == '‚≠ê –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞' or text == '–æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞':
        quality_analysis = analyze_quality_metrics(df)
        await update.message.reply_text(quality_analysis, parse_mode='Markdown')
        return
        
    elif text == '‚è∞ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è' or text == '–≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è':
        col = COLUMN_SYNONYMS['–æ—á–µ—Ä–µ–¥—å']
        freq = df[col].value_counts()
        if len(freq) > 0:
            buf = plot_bar(df, col, '–í—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –≤ –æ—á–µ—Ä–µ–¥–∏')
            if buf:
                await update.message.reply_photo(buf)
                analysis = smart_analytics_gpt('–î–∞–π –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –æ–∂–∏–¥–∞–Ω–∏—è –≤ –æ—á–µ—Ä–µ–¥–∏', df)
                await update.message.reply_text(analysis)
            else:
                await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫ - –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
        else:
            await update.message.reply_text("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –≤—Ä–µ–º–µ–Ω–∏ –æ–∂–∏–¥–∞–Ω–∏—è")
        return
        
    elif text == 'üîç –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑' or text == '–¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑':
        detailed_analysis = generate_detailed_analysis(df)
        await update.message.reply_text(detailed_analysis, parse_mode='Markdown')
        return
        
    elif text == 'üìã –≤—Å–µ –≤–æ–ø—Ä–æ—Å—ã' or text == '–≤—Å–µ –≤–æ–ø—Ä–æ—Å—ã':
        questions_list = generate_questions_list(df)
        await update.message.reply_text(questions_list, parse_mode='Markdown')
        return

    # –°—Ç–∞—Ä—ã–µ –∫–Ω–æ–ø–∫–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    if text == '–æ—Ç—á–µ—Ç –ø–æ –æ–ø—Ä–æ—Å—É':
        summary = analyze_survey(df)
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω—ã–π –æ—Ç—á–µ—Ç –Ω–∞ —á–∞—Å—Ç–∏
        if len(summary) > 4000:
            parts = []
            current_part = ""
            lines = summary.split('\n')
            
            for line in lines:
                if len(current_part + line + '\n') > 4000:
                    parts.append(current_part)
                    current_part = line + '\n'
                else:
                    current_part += line + '\n'
            
            if current_part:
                parts.append(current_part)
            
            for i, part in enumerate(parts, 1):
                if len(parts) > 1:
                    header = f"üìä –û–¢–ß–ï–¢ –ü–û –û–ü–†–û–°–£ (—á–∞—Å—Ç—å {i}/{len(parts)})\n{'='*30}\n\n"
                    await update.message.reply_text(header + part)
                else:
                    await update.message.reply_text(part)
        else:
            await update.message.reply_text(summary)
        return
    elif text == '–≥–µ–Ω–¥–µ—Ä–Ω—ã–π pie chart':
        col = COLUMN_SYNONYMS['–ø–æ–ª']
        freq = df[col].value_counts()
        
        if len(freq) > 0:
            buf = plot_pie(df, col, '–ì–µ–Ω–¥–µ—Ä–Ω—ã–π —Å–æ—Å—Ç–∞–≤')
            if buf:
                await update.message.reply_photo(buf)
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                total = freq.sum()
                male_count = freq.get('–ú—É–∂—Å–∫–æ–π', 0)
                female_count = freq.get('–ñ–µ–Ω—Å–∫–∏–π', 0)
                
                stats_text = f"üë• –ì–ï–ù–î–ï–†–ù–´–ô –°–û–°–¢–ê–í –û–ü–†–û–®–ï–ù–ù–´–•\n\n"
                stats_text += f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\n"
                stats_text += f"‚Ä¢ –í—Å–µ–≥–æ –æ—Ç–≤–µ—Ç–æ–≤: {total}\n"
                stats_text += f"‚Ä¢ –ú—É–∂—á–∏–Ω: {male_count} ({male_count/total*100:.1f}%)\n"
                stats_text += f"‚Ä¢ –ñ–µ–Ω—â–∏–Ω: {female_count} ({female_count/total*100:.1f}%)\n\n"
                
                if male_count > female_count:
                    stats_text += f"üèÜ –ë–æ–ª—å—à–µ –º—É–∂—á–∏–Ω –Ω–∞ {male_count - female_count} —á–µ–ª–æ–≤–µ–∫"
                elif female_count > male_count:
                    stats_text += f"üèÜ –ë–æ–ª—å—à–µ –∂–µ–Ω—â–∏–Ω –Ω–∞ {female_count - male_count} —á–µ–ª–æ–≤–µ–∫"
                else:
                    stats_text += f"‚öñÔ∏è –†–∞–≤–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º—É–∂—á–∏–Ω –∏ –∂–µ–Ω—â–∏–Ω"
                
                await update.message.reply_text(stats_text)
            else:
                await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫ - –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
        else:
            await update.message.reply_text("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ–ª–µ —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–æ–≤")
        return
    elif text == '–≤–æ–∑—Ä–∞—Å—Ç: histogram':
        col = COLUMN_SYNONYMS['–≤–æ–∑—Ä–∞—Å—Ç']
        numeric_data = extract_numeric(df[col]).dropna()
        
        if len(numeric_data) > 0:
            buf = plot_hist(df, col, '–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –≤–æ–∑—Ä–∞—Å—Ç—É')
            if buf:
                await update.message.reply_photo(buf)
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                stats_text = f"üìä –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –í–û–ó–†–ê–°–¢–£\n\n"
                stats_text += f"üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\n"
                stats_text += f"‚Ä¢ –í—Å–µ–≥–æ –æ—Ç–≤–µ—Ç–æ–≤: {len(numeric_data)}\n"
                stats_text += f"‚Ä¢ –°—Ä–µ–¥–Ω–∏–π –≤–æ–∑—Ä–∞—Å—Ç: {numeric_data.mean():.1f} –ª–µ—Ç\n"
                stats_text += f"‚Ä¢ –ú–µ–¥–∏–∞–Ω–Ω—ã–π –≤–æ–∑—Ä–∞—Å—Ç: {numeric_data.median():.1f} –ª–µ—Ç\n"
                stats_text += f"‚Ä¢ –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –≤–æ–∑—Ä–∞—Å—Ç: {numeric_data.min()} –ª–µ—Ç\n"
                stats_text += f"‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –≤–æ–∑—Ä–∞—Å—Ç: {numeric_data.max()} –ª–µ—Ç\n\n"
                
                # –¢–æ–ø –≤–æ–∑—Ä–∞—Å—Ç–æ–≤
                age_counts = numeric_data.value_counts().head(3)
                stats_text += f"üèÜ –°–∞–º—ã–µ —á–∞—Å—Ç—ã–µ –≤–æ–∑—Ä–∞—Å—Ç—ã:\n"
                for i, (age, count) in enumerate(age_counts.items(), 1):
                    stats_text += f"{i}. {age} –ª–µ—Ç: {count} —á–µ–ª–æ–≤–µ–∫\n"
                
                await update.message.reply_text(stats_text)
            else:
                await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫ - –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
        else:
            await update.message.reply_text("–ù–µ—Ç —á–∏—Å–ª–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –æ –≤–æ–∑—Ä–∞—Å—Ç–µ")
        return
    elif text == '—Ç–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è: bar chart':
        col = COLUMN_SYNONYMS['—Ç–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è']
        buf = plot_bar(df, col, '–¢–∏–ø—ã –æ–±—Ä–∞—â–µ–Ω–∏–π')
        if buf:
            await update.message.reply_photo(buf)
            analysis = smart_analytics_gpt('–î–∞–π –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø–∞–º –æ–±—Ä–∞—â–µ–Ω–∏–π', df)
            await update.message.reply_text(analysis)
        else:
            await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫ - –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
        return
    elif text == '—Ç–æ–ø –±–∞–Ω–∫–æ–≤: bar chart':
        col = COLUMN_SYNONYMS['–±–∞–Ω–∫']
        buf = plot_bar(df, col, '–¢–æ–ø –ø–æ—Å–µ—â–∞–µ–º—ã—Ö –±–∞–Ω–∫–æ–≤')
        if buf:
            await update.message.reply_photo(buf)
            analysis = smart_analytics_gpt('–î–∞–π –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ –ø–æ —Ç–æ–ø—É –±–∞–Ω–∫–æ–≤', df)
            await update.message.reply_text(analysis)
        else:
            await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫ - –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
        return

    # --- –õ—é–±–æ–π –¥—Ä—É–≥–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å ---
    try:
        reply = smart_analytics_gpt(update.message.text, df)
        await update.message.reply_text(reply)
    except Exception as e:
        await update.message.reply_text("–ù–µ —Å–º–æ–≥ –ø–æ–ª—É—á–∏—Ç—å —É–º–Ω—ã–π –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–Ω–∞—á–µ!\n–û—à–∏–±–∫–∞: " + str(e))

def analyze_survey(df):
    summary = f"üìä –û–¢–ß–ï–¢ –ü–û –û–ü–†–û–°–£ –ë–ê–ù–ö–û–í–°–ö–ò–• –ö–õ–ò–ï–ù–¢–û–í\n"
    summary += f"{'='*50}\n\n"
    summary += f"üìà –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\n"
    summary += f"‚Ä¢ –í—Å–µ–≥–æ –∞–Ω–∫–µ—Ç: {len(df)}\n"
    summary += f"‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤: {len(df.columns)}\n\n"
    
    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ–ª–æ–Ω–∫—É —Å –æ—Ç–º–µ—Ç–∫–æ–π –≤—Ä–µ–º–µ–Ω–∏
    relevant_columns = [col for col in df.columns if '–æ—Ç–º–µ—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–∏' not in col.lower() and 'timestamp' not in col.lower()]
    
    summary += f"üîç –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:\n\n"
    
    for i, col in enumerate(relevant_columns, 1):
        val = df[col].value_counts()
        if val.shape[0] > 1:
            total = val.sum()
            top_answer = val.idxmax()
            top_count = val.max()
            top_percent = (top_count / total) * 100
            
            # –°–æ–∫—Ä–∞—â–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
            short_col = col
            if len(col) > 50:
                short_col = col[:47] + "..."
            
            summary += f"{i}. {short_col}\n"
            summary += f"   üìä –í—Å–µ–≥–æ –æ—Ç–≤–µ—Ç–æ–≤: {total}\n"
            summary += f"   üèÜ –¢–æ–ø –æ—Ç–≤–µ—Ç: '{top_answer}' ({top_count} —Ä–∞–∑, {top_percent:.1f}%)\n"
            
            if len(val) <= 4:
                summary += f"   üìã –í—Å–µ –æ—Ç–≤–µ—Ç—ã:\n"
                for answer, count in val.items():
                    percent = (count / total) * 100
                    summary += f"      ‚Ä¢ {answer}: {count} ({percent:.1f}%)\n"
            else:
                summary += f"   üìã –¢–æ–ø-3 –æ—Ç–≤–µ—Ç–∞:\n"
                for j, (answer, count) in enumerate(val.head(3).items(), 1):
                    percent = (count / total) * 100
                    summary += f"      {j}. {answer}: {count} ({percent:.1f}%)\n"
            
            summary += "\n"
    
    summary += f"üí° –•–æ—Ç–∏—Ç–µ —É–≤–∏–¥–µ—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏? –ù–∞–ø–∏—à–∏—Ç–µ:\n"
    summary += f"‚Ä¢ '–≥—Ä–∞—Ñ–∏–∫ –ø–æ –±–∞–Ω–∫–∞–º'\n"
    summary += f"‚Ä¢ '—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤–æ–∑—Ä–∞—Å—Ç—É'\n"
    summary += f"‚Ä¢ '–∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º'\n"
    summary += f"‚Ä¢ '—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º—É–∂—á–∏–Ω –∏ –∂–µ–Ω—â–∏–Ω'"
    
    return summary

def generate_quick_analysis(df):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –±—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫"""
    analysis = f"üéØ *–ë–´–°–¢–†–´–ô –ê–ù–ê–õ–ò–ó –ö–õ–Æ–ß–ï–í–´–• –ú–ï–¢–†–ò–ö*\n\n"
    
    # –ê–Ω–∞–ª–∏–∑ –±–∞–Ω–∫–æ–≤
    bank_col = COLUMN_SYNONYMS.get('–±–∞–Ω–∫')
    if bank_col and bank_col in df.columns:
        bank_freq = df[bank_col].value_counts()
        if len(bank_freq) > 0:
            top_bank = bank_freq.idxmax()
            top_count = bank_freq.max()
            total_banks = bank_freq.sum()
            analysis += f"üè¶ *–¢–æ–ø –±–∞–Ω–∫:* {top_bank} ({top_count}/{total_banks} –∫–ª–∏–µ–Ω—Ç–æ–≤)\n\n"
    
    # –ê–Ω–∞–ª–∏–∑ –≤–æ–∑—Ä–∞—Å—Ç–∞
    age_col = COLUMN_SYNONYMS.get('–≤–æ–∑—Ä–∞—Å—Ç')
    if age_col and age_col in df.columns:
        age_data = extract_numeric(df[age_col]).dropna()
        if len(age_data) > 0:
            avg_age = age_data.mean()
            analysis += f"üìä *–°—Ä–µ–¥–Ω–∏–π –≤–æ–∑—Ä–∞—Å—Ç:* {avg_age:.1f} –ª–µ—Ç\n\n"
    
    # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è
    quality_cols = {
        '–≤–µ–∂–ª–∏–≤–æ—Å—Ç—å': '–í–µ–∂–ª–∏–≤–æ—Å—Ç—å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤',
        '–∫–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å': '–ö–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å',
        '–ø–æ–Ω—è—Ç–Ω–æ': '–ü–æ–Ω—è—Ç–Ω–æ—Å—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏–π',
        '—á–∏—Å—Ç–æ—Ç–∞': '–ß–∏—Å—Ç–æ—Ç–∞ –ø–æ–º–µ—â–µ–Ω–∏–π'
    }
    
    analysis += f"‚≠ê *–û—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞:*\n"
    for key, name in quality_cols.items():
        col = COLUMN_SYNONYMS.get(key)
        if col and col in df.columns:
            freq = df[col].value_counts()
            if len(freq) > 0:
                positive_answers = freq.get('–û—á–µ–Ω—å –≤–µ–∂–ª–∏–≤—ã', 0) + freq.get('–í–µ–∂–ª–∏–≤—ã', 0) + freq.get('–í—ã—Å–æ–∫–∞—è', 0) + freq.get('–û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è', 0) + freq.get('–û—á–µ–Ω—å –ø–æ–Ω—è—Ç–Ω–æ', 0) + freq.get('–ü–æ–Ω—è—Ç–Ω–æ', 0) + freq.get('–û—Ç–ª–∏—á–Ω–æ', 0) + freq.get('–•–æ—Ä–æ—à–æ', 0)
                total = freq.sum()
                positive_percent = (positive_answers / total) * 100 if total > 0 else 0
                analysis += f"‚Ä¢ {name}: {positive_percent:.1f}% –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫\n"
    
    # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º
    problem_col = COLUMN_SYNONYMS.get('–ø—Ä–æ–±–ª–µ–º')
    if problem_col and problem_col in df.columns:
        problem_freq = df[problem_col].value_counts()
        if len(problem_freq) > 0:
            no_problems = problem_freq.get('–ù–µ—Ç, –≤—Å–µ –≤–æ–ø—Ä–æ—Å—ã —Ä–µ—à–µ–Ω—ã', 0)
            total_problems = problem_freq.sum()
            success_rate = (no_problems / total_problems) * 100 if total_problems > 0 else 0
            analysis += f"\n‚úÖ *–£—Å–ø–µ—à–Ω–æ—Å—Ç—å —Ä–µ—à–µ–Ω–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤:* {success_rate:.1f}%\n"
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    rec_col = COLUMN_SYNONYMS.get('—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è')
    if rec_col and rec_col in df.columns:
        rec_freq = df[rec_col].value_counts()
        if len(rec_freq) > 0:
            positive_rec = rec_freq.get('–û–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ –¥–∞', 0) + rec_freq.get('–°–∫–æ—Ä–µ–µ –¥–∞', 0)
            total_rec = rec_freq.sum()
            rec_percent = (positive_rec / total_rec) * 100 if total_rec > 0 else 0
            analysis += f"üëç *–ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞—Ç—å:* {rec_percent:.1f}%\n"
    
    analysis += f"\nüí° *–í—ã–≤–æ–¥—ã:*\n"
    analysis += f"‚Ä¢ –û–±—â–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è –≤—ã—Å–æ–∫–æ–µ\n"
    analysis += f"‚Ä¢ –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –∫–ª–∏–µ–Ω—Ç–æ–≤ –¥–æ–≤–æ–ª—å–Ω—ã\n"
    analysis += f"‚Ä¢ –ï—Å—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏\n"
    
    return analysis

def analyze_quality_metrics(df):
    """–ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è"""
    analysis = f"‚≠ê *–ê–ù–ê–õ–ò–ó –ö–ê–ß–ï–°–¢–í–ê –û–ë–°–õ–£–ñ–ò–í–ê–ù–ò–Ø*\n\n"
    
    quality_metrics = {
        '–≤–µ–∂–ª–∏–≤–æ—Å—Ç—å': '–í–µ–∂–ª–∏–≤–æ—Å—Ç—å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤',
        '–∫–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å': '–ö–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤', 
        '–ø–æ–Ω—è—Ç–Ω–æ': '–ü–æ–Ω—è—Ç–Ω–æ—Å—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏–π',
        '—á–∏—Å—Ç–æ—Ç–∞': '–ß–∏—Å—Ç–æ—Ç–∞ –∏ –∫–æ–º—Ñ–æ—Ä—Ç',
        '–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å': '–î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏',
        '—Ç–µ—Ä–º–∏–Ω–∞–ª': '–£–¥–æ–±—Å—Ç–≤–æ —Ç–µ—Ä–º–∏–Ω–∞–ª–æ–≤'
    }
    
    total_scores = {}
    
    for key, name in quality_metrics.items():
        col = COLUMN_SYNONYMS.get(key)
        if col and col in df.columns:
            freq = df[col].value_counts()
            if len(freq) > 0:
                total = freq.sum()
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –º–µ—Ç—Ä–∏–∫–∞
                positive_answers = 0
                if key == '–≤–µ–∂–ª–∏–≤–æ—Å—Ç—å':
                    positive_answers = freq.get('–û—á–µ–Ω—å –≤–µ–∂–ª–∏–≤—ã', 0) + freq.get('–í–µ–∂–ª–∏–≤—ã', 0)
                elif key == '–∫–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å':
                    positive_answers = freq.get('–í—ã—Å–æ–∫–∞—è', 0) + freq.get('–û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è', 0)
                elif key == '–ø–æ–Ω—è—Ç–Ω–æ':
                    positive_answers = freq.get('–û—á–µ–Ω—å –ø–æ–Ω—è—Ç–Ω–æ', 0) + freq.get('–ü–æ–Ω—è—Ç–Ω–æ', 0)
                elif key == '—á–∏—Å—Ç–æ—Ç–∞':
                    positive_answers = freq.get('–û—Ç–ª–∏—á–Ω–æ', 0) + freq.get('–•–æ—Ä–æ—à–æ', 0)
                elif key == '–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å':
                    positive_answers = freq.get('–û—á–µ–Ω—å –¥–æ—Å—Ç—É–ø–Ω–∞', 0) + freq.get('–î–æ—Å—Ç—É–ø–Ω–∞', 0)
                elif key == '—Ç–µ—Ä–º–∏–Ω–∞–ª':
                    positive_answers = freq.get('–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ', 0) + freq.get('–£–¥–æ–±–Ω–æ', 0)
                
                positive_percent = (positive_answers / total) * 100 if total > 0 else 0
                total_scores[key] = positive_percent
                
                # –≠–º–æ–¥–∑–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏
                if positive_percent >= 80:
                    emoji = "üü¢"
                elif positive_percent >= 60:
                    emoji = "üü°"
                else:
                    emoji = "üî¥"
                
                analysis += f"{emoji} *{name}:* {positive_percent:.1f}% –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫\n"
    
    # –û–±—â–∏–π —Ä–µ–π—Ç–∏–Ω–≥
    if total_scores:
        avg_score = sum(total_scores.values()) / len(total_scores)
        analysis += f"\nüìä *–û–ë–©–ò–ô –†–ï–ô–¢–ò–ù–ì –ö–ê–ß–ï–°–¢–í–ê:* {avg_score:.1f}%\n\n"
        
        if avg_score >= 80:
            analysis += f"üèÜ *–û—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è!*\n"
        elif avg_score >= 60:
            analysis += f"‚ö†Ô∏è *–•–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –µ—Å—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è*\n"
        else:
            analysis += f"‚ùå *–¢—Ä–µ–±—É–µ—Ç—Å—è —Å–µ—Ä—å–µ–∑–Ω–∞—è —Ä–∞–±–æ—Ç–∞ –Ω–∞–¥ –∫–∞—á–µ—Å—Ç–≤–æ–º*\n"
    
    return analysis

def generate_detailed_analysis(df):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏"""
    analysis = f"üîç *–î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –û–ü–†–û–°–ê*\n\n"
    
    # –î–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
    analysis += f"üë• *–î–ï–ú–û–ì–†–ê–§–ò–Ø:*\n"
    
    gender_col = COLUMN_SYNONYMS.get('–ø–æ–ª')
    if gender_col and gender_col in df.columns:
        gender_freq = df[gender_col].value_counts()
        if len(gender_freq) > 0:
            male = gender_freq.get('–ú—É–∂—Å–∫–æ–π', 0)
            female = gender_freq.get('–ñ–µ–Ω—Å–∫–∏–π', 0)
            total = gender_freq.sum()
            analysis += f"‚Ä¢ –ú—É–∂—á–∏–Ω: {male} ({male/total*100:.1f}%)\n"
            analysis += f"‚Ä¢ –ñ–µ–Ω—â–∏–Ω: {female} ({female/total*100:.1f}%)\n\n"
    
    # –ê–Ω–∞–ª–∏–∑ –±–∞–Ω–∫–æ–≤
    analysis += f"üè¶ *–ê–ù–ê–õ–ò–ó –ë–ê–ù–ö–û–í:*\n"
    bank_col = COLUMN_SYNONYMS.get('–±–∞–Ω–∫')
    if bank_col and bank_col in df.columns:
        bank_freq = df[bank_col].value_counts()
        if len(bank_freq) > 0:
            for i, (bank, count) in enumerate(bank_freq.head(3).items(), 1):
                percent = (count / bank_freq.sum()) * 100
                analysis += f"{i}. {bank}: {count} –∫–ª–∏–µ–Ω—Ç–æ–≤ ({percent:.1f}%)\n"
            analysis += "\n"
    
    # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º
    analysis += f"‚ö†Ô∏è *–ê–ù–ê–õ–ò–ó –ü–†–û–ë–õ–ï–ú:*\n"
    problem_col = COLUMN_SYNONYMS.get('–ø—Ä–æ–±–ª–µ–º')
    if problem_col and problem_col in df.columns:
        problem_freq = df[problem_col].value_counts()
        if len(problem_freq) > 0:
            for problem, count in problem_freq.items():
                percent = (count / problem_freq.sum()) * 100
                analysis += f"‚Ä¢ {problem}: {count} ({percent:.1f}%)\n"
            analysis += "\n"
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    analysis += f"üí° *–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:*\n"
    analysis += f"1. –£–ª—É—á—à–∏—Ç—å —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è\n"
    analysis += f"2. –£–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –≤ –ø–∏–∫–æ–≤—ã–µ —á–∞—Å—ã\n"
    analysis += f"3. –£–ª—É—á—à–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–µ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ\n"
    analysis += f"4. –ü—Ä–æ–≤–µ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–ª–∞\n"
    analysis += f"5. –ú–æ–¥–µ—Ä–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ—Ä–º–∏–Ω–∞–ª—ã\n\n"
    
    analysis += f"üìà *–ü–û–¢–ï–ù–¶–ò–ê–õ –†–û–°–¢–ê:*\n"
    analysis += f"‚Ä¢ –ü–æ–≤—ã—à–µ–Ω–∏–µ —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤\n"
    analysis += f"‚Ä¢ –£–≤–µ–ª–∏—á–µ–Ω–∏–µ –ª–æ—è–ª—å–Ω–æ—Å—Ç–∏\n"
    analysis += f"‚Ä¢ –†–æ—Å—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π\n"
    analysis += f"‚Ä¢ –°–Ω–∏–∂–µ–Ω–∏–µ –∂–∞–ª–æ–±\n"
    
    return analysis

def generate_questions_list(df):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ —Å –∫—Ä–∞—Ç–∫–∏–º –æ–ø–∏—Å–∞–Ω–∏–µ–º"""
    questions = f"üìã *–°–ü–ò–°–û–ö –í–°–ï–• –í–û–ü–†–û–°–û–í –û–ü–†–û–°–ê*\n\n"
    
    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ç–º–µ—Ç–∫—É –≤—Ä–µ–º–µ–Ω–∏
    relevant_columns = [col for col in df.columns if '–æ—Ç–º–µ—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–∏' not in col.lower() and 'timestamp' not in col.lower()]
    
    for i, col in enumerate(relevant_columns, 1):
        val = df[col].value_counts()
        total = val.sum() if len(val) > 0 else 0
        
        questions += f"{i}. *{col}*\n"
        questions += f"   üìä –û—Ç–≤–µ—Ç–æ–≤: {total}\n"
        
        if len(val) > 0:
            top_answer = val.idxmax()
            questions += f"   üèÜ –¢–æ–ø –æ—Ç–≤–µ—Ç: {top_answer}\n"
        
        questions += "\n"
    
    questions += f"üí° *–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:*\n"
    questions += f"‚Ä¢ –ù–∞–ø–∏—à–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–∞ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏\n"
    questions += f"‚Ä¢ –î–æ–±–∞–≤—å—Ç–µ '–≥—Ä–∞—Ñ–∏–∫' –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏\n"
    questions += f"‚Ä¢ –î–æ–±–∞–≤—å—Ç–µ '–∞–Ω–∞–ª–∏–∑' –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è\n"
    
    return questions

def generate_comparison_analysis(df, column):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∞–Ω–∞–ª–∏–∑ —Å—Ä–∞–≤–Ω–µ–Ω–∏–π –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏"""
    comparison = f"üìä *–°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó: {column}*\n\n"
    
    freq = df[column].value_counts()
    if len(freq) < 2:
        return f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –≤ –∫–æ–ª–æ–Ω–∫–µ '{column}'"
    
    total = freq.sum()
    
    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ç–æ–ø-2 –æ—Ç–≤–µ—Ç–∞
    top_answers = freq.head(2)
    first_answer, first_count = top_answers.iloc[0], top_answers.index[0]
    second_answer, second_count = top_answers.iloc[1], top_answers.index[1]
    
    first_percent = (first_count / total) * 100
    second_percent = (second_count / total) * 100
    difference = first_count - second_count
    difference_percent = first_percent - second_percent
    
    comparison += f"üèÜ *–¢–æ–ø-2 –æ—Ç–≤–µ—Ç–∞:*\n"
    comparison += f"1. {first_answer}: {first_count} ({first_percent:.1f}%)\n"
    comparison += f"2. {second_answer}: {second_count} ({second_percent:.1f}%)\n\n"
    
    comparison += f"üìà *–†–∞–∑–Ω–∏—Ü–∞:*\n"
    comparison += f"‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è: {difference} –æ—Ç–≤–µ—Ç–æ–≤\n"
    comparison += f"‚Ä¢ –ü—Ä–æ—Ü–µ–Ω—Ç–Ω–∞—è: {difference_percent:.1f}%\n\n"
    
    if difference_percent > 20:
        comparison += f"üí° *–í—ã–≤–æ–¥:* {first_answer} –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–æ–±–ª–∞–¥–∞–µ—Ç\n"
    elif difference_percent > 10:
        comparison += f"üí° *–í—ã–≤–æ–¥:* {first_answer} —É–º–µ—Ä–µ–Ω–Ω–æ –ª–∏–¥–∏—Ä—É–µ—Ç\n"
    else:
        comparison += f"üí° *–í—ã–≤–æ–¥:* –û—Ç–≤–µ—Ç—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω—ã —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ\n"
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å –±–æ–ª—å—à–µ –æ—Ç–≤–µ—Ç–æ–≤, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–ª–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
    if len(freq) > 2:
        comparison += f"\nüìã *–ü–æ–ª–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:*\n"
        for i, (answer, count) in enumerate(freq.items(), 1):
            percent = (count / total) * 100
            comparison += f"{i}. {answer}: {count} ({percent:.1f}%)\n"
    
    return comparison

def generate_recommendations(df, column):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–∫–∏"""
    recommendations = f"üí° *–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û: {column}*\n\n"
    
    freq = df[column].value_counts()
    if len(freq) == 0:
        return f"‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤ –∫–æ–ª–æ–Ω–∫–µ '{column}'"
    
    total = freq.sum()
    top_answer = freq.idxmax()
    top_count = freq.max()
    top_percent = (top_count / total) * 100
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∫–æ–ª–æ–Ω–∫–∏ –∏ –¥–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    column_lower = column.lower()
    
    if '–±–∞–Ω–∫' in column_lower:
        recommendations += f"üè¶ *–ê–Ω–∞–ª–∏–∑ –±–∞–Ω–∫–æ–≤:*\n"
        recommendations += f"‚Ä¢ –õ–∏–¥–µ—Ä: {top_answer} ({top_percent:.1f}% –∫–ª–∏–µ–Ω—Ç–æ–≤)\n\n"
        recommendations += f"üìã *–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:*\n"
        recommendations += f"1. –ò–∑—É—á–∏—Ç—å –æ–ø—ã—Ç –ª–∏–¥–∏—Ä—É—é—â–µ–≥–æ –±–∞–Ω–∫–∞\n"
        recommendations += f"2. –ü—Ä–æ–≤–µ—Å—Ç–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑\n"
        recommendations += f"3. –£–ª—É—á—à–∏—Ç—å —Å–µ—Ä–≤–∏—Å—ã –≤ –æ—Ç—Å—Ç–∞—é—â–∏—Ö –±–∞–Ω–∫–∞—Ö\n"
        recommendations += f"4. –†–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è\n"
        
    elif '–≤–æ–∑—Ä–∞—Å—Ç' in column_lower:
        recommendations += f"üìä *–ê–Ω–∞–ª–∏–∑ –≤–æ–∑—Ä–∞—Å—Ç–∞:*\n"
        recommendations += f"‚Ä¢ –°–∞–º—ã–π —á–∞—Å—Ç—ã–π –≤–æ–∑—Ä–∞—Å—Ç: {top_answer} –ª–µ—Ç\n\n"
        recommendations += f"üìã *–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:*\n"
        recommendations += f"1. –ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å —É—Å–ª—É–≥–∏ –ø–æ–¥ —Ü–µ–ª–µ–≤—É—é –∞—É–¥–∏—Ç–æ—Ä–∏—é\n"
        recommendations += f"2. –†–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å –ø—Ä–æ–≥—Ä–∞–º–º—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –≤–æ–∑—Ä–∞—Å—Ç–Ω—ã—Ö –≥—Ä—É–ø–ø\n"
        recommendations += f"3. –£–ª—É—á—à–∏—Ç—å —Ü–∏—Ñ—Ä–æ–≤—ã–µ –∫–∞–Ω–∞–ª—ã –¥–ª—è –º–æ–ª–æ–¥–µ–∂–∏\n"
        recommendations += f"4. –°–æ–∑–¥–∞—Ç—å —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–ª—è —Å—Ç–∞—Ä—à–µ–≥–æ –≤–æ–∑—Ä–∞—Å—Ç–∞\n"
        
    elif '–ø–æ–ª' in column_lower:
        recommendations += f"üë• *–ê–Ω–∞–ª–∏–∑ –≥–µ–Ω–¥–µ—Ä–∞:*\n"
        recommendations += f"‚Ä¢ –ü—Ä–µ–æ–±–ª–∞–¥–∞–µ—Ç: {top_answer}\n\n"
        recommendations += f"üìã *–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:*\n"
        recommendations += f"1. –†–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å –≥–µ–Ω–¥–µ—Ä–Ω–æ-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã\n"
        recommendations += f"2. –ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã–µ –∫–∞–º–ø–∞–Ω–∏–∏\n"
        recommendations += f"3. –£–ª—É—á—à–∏—Ç—å –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –¥–ª—è –º–µ–Ω—å—à–∏–Ω—Å—Ç–≤–∞\n"
        recommendations += f"4. –ü—Ä–æ–≤–µ—Å—Ç–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–µ–π\n"
        
    elif '–∫–∞—á–µ—Å—Ç–≤–æ' in column_lower or '–æ—Ü–µ–Ω–∫–∞' in column_lower or '—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–µ–Ω–Ω–æ—Å—Ç—å' in column_lower:
        recommendations += f"‚≠ê *–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞:*\n"
        recommendations += f"‚Ä¢ –û—Å–Ω–æ–≤–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: {top_answer}\n\n"
        recommendations += f"üìã *–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:*\n"
        recommendations += f"1. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å –≤—ã—Å–æ–∫–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã\n"
        recommendations += f"2. –£–ª—É—á—à–∏—Ç—å –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏\n"
        recommendations += f"3. –ü—Ä–æ–≤–µ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–ª–∞\n"
        recommendations += f"4. –í–Ω–µ–¥—Ä–∏—Ç—å —Å–∏—Å—Ç–µ–º—É –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏\n"
        
    elif '–ø—Ä–æ–±–ª–µ–º' in column_lower or '–∂–∞–ª–æ–±' in column_lower:
        recommendations += f"‚ö†Ô∏è *–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º:*\n"
        recommendations += f"‚Ä¢ –û—Å–Ω–æ–≤–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞: {top_answer}\n\n"
        recommendations += f"üìã *–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:*\n"
        recommendations += f"1. –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ—à–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º\n"
        recommendations += f"2. –£–ª—É—á—à–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å—ã –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è\n"
        recommendations += f"3. –£–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä—Å–æ–Ω–∞–ª–∞\n"
        recommendations += f"4. –í–Ω–µ–¥—Ä–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—é\n"
        
    else:
        recommendations += f"üìä *–û–±—â–∏–π –∞–Ω–∞–ª–∏–∑:*\n"
        recommendations += f"‚Ä¢ –¢–æ–ø –æ—Ç–≤–µ—Ç: {top_answer} ({top_percent:.1f}%)\n\n"
        recommendations += f"üìã *–û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:*\n"
        recommendations += f"1. –ò–∑—É—á–∏—Ç—å –ø—Ä–∏—á–∏–Ω—ã –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏ —Ç–æ–ø-–æ—Ç–≤–µ—Ç–∞\n"
        recommendations += f"2. –£–ª—É—á—à–∏—Ç—å –º–µ–Ω–µ–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã\n"
        recommendations += f"3. –ü—Ä–æ–≤–µ—Å—Ç–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ\n"
        recommendations += f"4. –†–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —Ä–∞–∑–≤–∏—Ç–∏—è\n"
    
    recommendations += f"\nüéØ *–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:*\n"
    recommendations += f"‚Ä¢ –ü—Ä–æ–≤–µ—Å—Ç–∏ –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑\n"
    recommendations += f"‚Ä¢ –†–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å –ø–ª–∞–Ω –¥–µ–π—Å—Ç–≤–∏–π\n"
    recommendations += f"‚Ä¢ –ò–∑–º–µ—Ä–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑–º–µ–Ω–µ–Ω–∏–π\n"
    
    return recommendations

def main():
    app = Application.builder().token(TELEGRAM_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & (~filters.COMMAND), handle_message))
    app.run_polling()

if __name__ == '__main__':
    main()